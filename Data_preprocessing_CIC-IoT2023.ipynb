{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae7268d",
   "metadata": {},
   "source": [
    "## Data Preprocessing CIC-IoT2023\n",
    "\n",
    "This section covers the preprocessing of the CIC-IoT2023 dataset after extracting its flow-level and packet-level features using the `Feature_extractor_flow_packet_combined.py` script (extraction shown in `GNN4ID.ipynb`). Since CIC-IoT2023 dataset is very huge and is very imbalance with having some classes with very low instances, therefore to maintain uniformity we have under and over-sampled data instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterate for each individual Class\n",
    "List_of_CSV_File =glob.glob(\"F:/CIC_IOT/Recon*\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c96a9",
   "metadata": {},
   "source": [
    "For our preprocessing, we divided the data into an 80:20 split. Specifically, 80% of the data is used for training, while the remaining 20% is utilized for testing.\n",
    "\n",
    "To achieve this division, we first identified the class with the least number of samples, which in our scenario was the BruteForce Attack class, with 2,336 samples. Using this as a reference point, we determined the undersampling rate for the other classes based on the number of samples for the minority class.\n",
    "\n",
    "We applied an oversampling factor of 10x to the minority class for the training data, meaning we increased the number of training samples for the BruteForce Attack class (80% of 2,336 samples) to 20,000 samples. Consequently, we limited the number of training samples for each class to 20,000. Depending on the class, we either undersampled or oversampled to achieve this target.\n",
    "\n",
    "The following steps outline the process of dividing the dataset into an 80:20 split and subsequently performing the necessary over/undersampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60665d1e",
   "metadata": {},
   "source": [
    "### Dataset Division & Filtering\n",
    "\n",
    "For Attack Data Only, We are filtering the attack data instances by removing all other flow isntances that does not have attacker mac address as either source or destination.\n",
    "\n",
    "Additionally, we are limiting the test dataset samples to maximum 4000 and training samples to 20,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a929ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterate for each file in List_of_CSV_File\n",
    "df = pd.read_csv(List_of_CSV_File[0])\n",
    "print(\"Size Before Filtering:\", df.shape)\n",
    "\n",
    "## Comment this line if Using for Benign Data.\n",
    "df=df[(df['src_mac']=='dc:a6:32:dc:27:d5') | (df['src_mac']=='e4:5f:01:55:90:c4') | (df['src_mac']=='dc:a6:32:c9:e4:ab') | (df['src_mac']=='ac:17:02:05:34:27') | (df['src_mac']=='dc:a6:32:c9:e5:a4') | (df['src_mac']=='dc:a6:32:c9:e4:d5') | (df['src_mac']=='dc:a6:32:c9:e5:ef') | (df['src_mac']=='dc:a6:32:c9:e4:90') | (df['src_mac']=='b0:09:da:3e:82:6c') | (df['dst_mac']=='dc:a6:32:dc:27:d5') | (df['dst_mac']=='e4:5f:01:55:90:c4') | (df['dst_mac']=='dc:a6:32:c9:e4:ab') | (df['dst_mac']=='ac:17:02:05:34:27') | (df['dst_mac']=='dc:a6:32:c9:e5:a4') | (df['dst_mac']=='dc:a6:32:c9:e4:d5') | (df['dst_mac']=='dc:a6:32:c9:e5:ef') | (df['dst_mac']=='dc:a6:32:c9:e4:90') | (df['dst_mac']=='b0:09:da:3e:82:6c') ]\n",
    "\n",
    "## Comment this line if Using for Attack Data\n",
    "# df=df[(df['src_mac']!='dc:a6:32:dc:27:d5') & (df['src_mac']!='e4:5f:01:55:90:c4') & (df['src_mac']!='dc:a6:32:c9:e4:ab') & (df['src_mac']!='ac:17:02:05:34:27') & (df['src_mac']!='dc:a6:32:c9:e5:a4') & (df['src_mac']!='dc:a6:32:c9:e4:d5') & (df['src_mac']!='dc:a6:32:c9:e5:ef') & (df['src_mac']!='dc:a6:32:c9:e4:90') & (df['src_mac']!='b0:09:da:3e:82:6c') & (df['dst_mac']!='dc:a6:32:dc:27:d5') & (df['dst_mac']!='e4:5f:01:55:90:c4') & (df['dst_mac']!='dc:a6:32:c9:e4:ab') & (df['dst_mac']!='ac:17:02:05:34:27') & (df['dst_mac']!='dc:a6:32:c9:e5:a4') & (df['dst_mac']!='dc:a6:32:c9:e4:d5') & (df['dst_mac']!='dc:a6:32:c9:e5:ef') & (df['dst_mac']!='dc:a6:32:c9:e4:90') & (df['dst_mac']!='b0:09:da:3e:82:6c') ]\n",
    "\n",
    "## Dropping Extra Columns that we are not utilizing in our graph data object\n",
    "df.drop(['src_ip','src_port','dst_ip','dst_port','ip_version'], axis=1, inplace=True)\n",
    "df.drop(['bidirectional_bytes','bidirectional_first_seen_ms','bidirectional_last_seen_ms','bidirectional_duration_ms',\n",
    "         'bidirectional_packets','src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms',\n",
    "         'id','src_mac','src_oui','dst_mac','dst_oui','vlan_id','tunnel_id','bidirectional_syn_packets','bidirectional_cwr_packets',\n",
    "         'bidirectional_ece_packets','bidirectional_urg_packets','bidirectional_ack_packets','bidirectional_psh_packets',\n",
    "         'bidirectional_rst_packets','bidirectional_fin_packets'], axis=1, inplace=True)\n",
    "\n",
    "## Making Sure the Feature Space reamain constant, therefore creating dummy variable with categories provided beforehand.\n",
    "df['expiration_id']=pd.Categorical(df['expiration_id'], categories=[0,-1])\n",
    "df['protocol']=pd.Categorical(df['protocol'], categories=[1,2,6,17,58])\n",
    "df=pd.get_dummies(df, prefix=['Exp','proto'], columns=['expiration_id', 'protocol'],dtype=int)\n",
    "print(\"Size After Filtering:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5862f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 10000/df.shape[0]\n",
    "df = df.sample(frac=fraction)\n",
    "df.to_csv(List_of_CSV_File[0], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e611e6",
   "metadata": {},
   "source": [
    "### Under/Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "id": "7c263583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:/GNN_Project/data/raw/test\\\\Benign_0_test.csv',\n",
       " 'F:/GNN_Project/data/raw/test\\\\Benign_1_test.csv',\n",
       " 'F:/GNN_Project/data/raw/test\\\\Benign_2_test.csv',\n",
       " 'F:/GNN_Project/data/raw/test\\\\Benign_3_test.csv']"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_of_CSV_File = glob.glob(\"F:/GNN_Project/data/raw/test/Benign*\") \n",
    "List_of_CSV_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56394f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4000 for test samples & 20000 for training samples\n",
    "Number_instances_in_each_Overall_Class = 4000\n",
    "Number_in_individaul_class =int(Number_instances_in_each_Overall_Class/len(List_of_CSV_File))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in List_of_CSV_File:\n",
    "    df = pd.read_csv(files)\n",
    "    name_file = files.split('\\\\')[-1]\n",
    "    name_file = name_file.split('.')[-2]\n",
    "    ## Remove _test if performing for training samples\n",
    "    name_file = os.path.dirname(files)+'\\\\'+name_file+'_test.csv'\n",
    "    if df.shape[0]<Number_in_individaul_class:\n",
    "        df = duplicate_rows(df,Number_in_individaul_class)\n",
    "    else:\n",
    "        fraction = Number_in_individaul_class/df.shape[0]\n",
    "        df = df.sample(frac=fraction)\n",
    "    df.to_csv(files, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75401a32",
   "metadata": {},
   "source": [
    "#### Combining Each Broad Class Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a223de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_of_CSV_File = glob.glob(\"F:/GNN_Project/data/raw/test/Benign*\") \n",
    "List_of_CSV_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e652a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [pd.read_csv(location) for location in List_of_CSV_File]\n",
    "concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
    "## Getting Name of the Broad_Class\n",
    "old_name_search = List_of_CSV_File[0].split('\\\\')[-1]\n",
    "old_name_search = old_name_search.split('.')[-2]\n",
    "old_name_search = re.sub(r'\\d+', '', old_name_search)\n",
    "old_name_search = old_name_search[:-1] if old_name_search.endswith(\"_\") else old_name_search\n",
    "try:\n",
    "    old_name_search = old_name_search.split('-')[-2]\n",
    "except:\n",
    "    old_name_search = old_name_search\n",
    "## Saving the File with Broad CLass and combined suffix\n",
    "concatenated_df.to_csv(os.path.dirname(List_of_CSV_File[0])+'\\\\'+old_name_search+'-Combined_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44481ae7",
   "metadata": {},
   "source": [
    "#### Combining Each Broad Class Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combined Data for Training\n",
    "List_of_CSV_File = glob.glob(\"F:/GNN_Project/data/raw/test/*.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da93c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate Over each file with new name\n",
    "df = pd.read_csv(List_of_CSV_File[0])\n",
    "# Iterate Label as per the Dictionary\n",
    "df['Label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_test=pd.concat([df,df1,df2,df3,df4,df5,df6,df7])\n",
    "df_complete.to_csv('/scratch/user/yasir.ali/GNN_Project/data/df_8_class_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
