{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec65361",
   "metadata": {},
   "source": [
    "## GNN4ID Heterogeneous Graph Model\n",
    "\n",
    "In this notebook, we provide instructions for using our developed heterogeneous graph models. We have created two different architectures:\n",
    "\n",
    "1. **Model without Edge Attributes**: In this model, edges provide only the connection information between nodes. This means the model focuses solely on the structural relationships within the graph.\n",
    "2. **Model with Edge Attributes**: In this model, edges have their own attributes/features in addition to providing connection information between nodes. This allows the model to leverage additional information carried by the edges, potentially improving its performance and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd313b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"G:/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a45f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utility.Functions import *\n",
    "from Utility.Model import *\n",
    "from Utility.Training import *\n",
    "from Utility.additional_features import *\n",
    "from Utility.llm_explanation import *\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import copy\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch_geometric.nn as pyg_nn\n",
    "# from torch_geometric.nn import global_mean_pool\n",
    "# from torch_sparse import SparseTensor, matmul\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import os\n",
    "# import glob\n",
    "# from torch_geometric.data import HeteroData\n",
    "# from torch_geometric.data import Dataset, Data\n",
    "# import sys\n",
    "# import torch_geometric.transforms as T\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix, f1_score,accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aec682",
   "metadata": {},
   "source": [
    "### Reading Graph Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad93a1d",
   "metadata": {},
   "source": [
    "**dir**: Where grapgh data is stored in processed folder.\n",
    "    data directory will have two folders inside: raw and processed.\n",
    "    graph objects will be stored in this processed folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1b8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_x = {'Benign': 0 , \n",
    "          'WebBased': 1, \n",
    "          'Spoofing': 2,\n",
    "          'Recon' : 3,\n",
    "          'Mirai' : 4,\n",
    "          'Dos' : 5,\n",
    "          'DDos' : 6,\n",
    "          'BruteForce': 7\n",
    "         }\n",
    "\n",
    "dir = \"F:/GNN_Project/data/\"\n",
    "Files =glob.glob(\"F:/GNN_Project/data_nate_approach/raw/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7c0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_x = {'Benign': 0 , \n",
    "          'WebBased': 1, \n",
    "          'Spoofing': 2,\n",
    "          'Recon' : 3,\n",
    "          'Mirai' : 4,\n",
    "          'Dos' : 5,\n",
    "          'DDos' : 6,\n",
    "          'BruteForce': 7\n",
    "         }\n",
    "\n",
    "dir = \"F:/GNN_Project/data/\" ## Directory where graph data will be stored\n",
    "Files =glob.glob(\"/scratch/user/yasir.ali/GNN_Project/data/raw/*.csv\") ## Directory where CSV files(Extracted Flow-level and packet-level inforamtion) is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70aa553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Hetero = NIDSDataset(root=dir, label_dict=Dict_x, filename=Files, skip_processing=True, test=False, single_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7201431",
   "metadata": {},
   "source": [
    "### Initializing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87747536",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arguments for running the model\n",
    "args = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'hidden_size': 64,\n",
    "    'epochs': 30,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr': 0.01,\n",
    "    'attn_size': 32,\n",
    "    'eps': 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a73a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing a Data Instance for Model Initialization\n",
    "data_model=data_Hetero[0].to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "968b29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model without edge attributes\n",
    "model = HeteroGNN(data_model, args, aggr=\"mean\").to(args['device'])\n",
    "\n",
    "## Model with Edge attributes\n",
    "# model = HeteroGNN_Edge(data_model, args, aggr=\"mean\").to(args['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e27156",
   "metadata": {},
   "source": [
    "### Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ab1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_Hetero, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the model without edge attributes\n",
    "train(train_loader, model, args, args[\"device\"])\n",
    "\n",
    "# # For training the model with edge attributes \n",
    "# train_with_edge_Att(train_loader, model, args, args[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8d1ff",
   "metadata": {},
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "115707d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Hetero = NIDSDataset(root=dir, label_dict=Dict_x, filename=Files, skip_processing=True, test=True, single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1532745",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For testing the model\n",
    "test_loader = DataLoader(data_Hetero, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ea4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing the model without edge attributes\n",
    "acc, prediction, label = test_cm(test_loader,model)\n",
    "\n",
    "# # For testing the model with edge attributes \n",
    "# acc, prediction, label = test_cm_with_edge_att(test_loader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b0734-1039-43f5-9e8f-5e3f5e36acf6",
   "metadata": {},
   "source": [
    "### LLM-based Explanation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d959ef-2e8d-4d4e-97a3-ee5c62e32b27",
   "metadata": {},
   "source": [
    "First we will initialize our llm model, either quantized fine-tuned version or base llm model from directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe7ae8-288f-4545-8934-2da20c4ac0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Quantized fine tuned version use this command\n",
    "llm_model,tokenizer=initialize_finetuned_llm(base_model_id = \"/scratch/user/syedwali/Python_env/myGNN/LLM/llama\",\n",
    "                            fine_tuned_directory=  \"/scratch/user/syedwali/llama2-7b-train-finetune/\")\n",
    "# Or we can use base model without quantization, model should be available in the local directory\n",
    "llm_model,tokenizer=initialize_llm(cache_dir = \"/scratch/user/syedwali/Python_env/myGNN/LLM/llama/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4d937-9bb7-46b8-8070-8ec9a94a6e0a",
   "metadata": {},
   "source": [
    "Now using test_with_explanation function we can generate LLM based explanations along with the GNN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62d7ca-a447-496b-9203-ec7ba8040221",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, prediction, label, explanation = test_with_explanation(test_loader,model,llm_model,tokenizer,fine_tune=False)\n",
    "# enable fine_tune if using quantized version "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae77f86",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "print(classification_report(label,prediction))\n",
    "print('\\n')\n",
    "print('                    Accuracy %',(round(accuracy_score(label,prediction),4)*100))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2363cf",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df69fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(label,prediction, normalize='true') ## Getting Results in Percentage \n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes()\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='.1%',ax=ax) # fmt= 'd' for just showing the value in int\n",
    "ax.set_ylabel('True Label') \n",
    "ax.set_xlabel('Predicted label')\n",
    "labels=['Benign','WebBased','Spoofing','Recon','Mirai','Dos','DDos','BruteForce']\n",
    "ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f2a5b",
   "metadata": {},
   "source": [
    "#### Saving/Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/scratch/user/yasir.ali/GNN_Project/Saved_Model/GNN4ID_8_Classes/model.pth')\n",
    "# model = torch.load('/scratch/user/yasir.ali/GNN_Project/Saved_Model/GNN4ID_8_Classes/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
